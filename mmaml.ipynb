{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accepting-resort",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "documented-florence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b24132754f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import *\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import config2 as config\n",
    "import MODEL\n",
    "import UTILS\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-batch",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "popular-dairy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(init=0, fold=0, few_shot_years=7, model_name='ctlstm', date='20230420')\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(\n",
    "#     description='arguments')\n",
    "# parser.add_argument('--init', type=int, default=0, help='init number')\n",
    "# parser.add_argument('--fold', type=int, default=0, help='fold number')\n",
    "# parser.add_argument('--few_shot_years', type=int, default=7, help='few_shot_years')\n",
    "# parser.add_argument('--model_name', type=str, default='ctlstm', help='model_name')\n",
    "# parser.add_argument('--date', type=str, default='20230420', help='date')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='arguments')\n",
    "\n",
    "# Define your command-line arguments\n",
    "parser.add_argument('--init', type=int, default=0, help='init number')\n",
    "parser.add_argument('--fold', type=int, default=0, help='fold number')\n",
    "parser.add_argument('--few_shot_years', type=int, default=7, help='few_shot_years')\n",
    "parser.add_argument('--model_name', type=str, default='ctlstm', help='model_name')\n",
    "parser.add_argument('--date', type=str, default='20230420', help='date')\n",
    "\n",
    "# Parse the arguments, ignoring the first one (which is the connection file passed by Jupyter)\n",
    "args = parser.parse_args(['--init', '0', '--fold', '0', '--few_shot_years', '7', '--model_name', 'ctlstm', '--date', '20230420'])\n",
    "\n",
    "# Now you can access the parsed arguments using args.init, args.fold, etc.\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceramic-division",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'config2' has no attribute 'static_channels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# CHANNELS INFO\u001b[39;00m\n\u001b[1;32m      6\u001b[0m dynamic_channels \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mdynamic_channels\n\u001b[0;32m----> 7\u001b[0m static_channels \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatic_channels\u001b[49m\n\u001b[1;32m      8\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39moutput_channels\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# LABELS INFO\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'config2' has no attribute 'static_channels'"
     ]
    }
   ],
   "source": [
    "# TIME SERIES INFO\n",
    "window = config.window\n",
    "stride = config.stride\n",
    "\n",
    "# CHANNELS INFO\n",
    "dynamic_channels = config.dynamic_channels\n",
    "static_channels = config.static_channels\n",
    "output_channels = config.output_channels\n",
    "\n",
    "# LABELS INFO\n",
    "unknown = config.unknown\n",
    "\n",
    "# MODEL INFO\n",
    "model_name = args.model_name\n",
    "forward_code_dim = config.forward_code_dim\n",
    "latent_code_dim = config.latent_code_dim\n",
    "device = torch.device(config.device)\n",
    "dropout = config.dropout\n",
    "\n",
    "# TRAIN INFO\n",
    "train = config.train\n",
    "batch_size = config.batch_size\n",
    "epochs = config.epochs\n",
    "learning_rate = config.learning_rate\n",
    "meta_learning_rate = config.meta_learning_rate\n",
    "num_inner_steps = 5\n",
    "init = args.init \n",
    "fold = args.fold\n",
    "max_patience = 10\n",
    "few_shot_years = args.few_shot_years\n",
    "\n",
    "print(\"Hyperparameters:{}\".format(model_name))\n",
    "print(\"window : {}\".format(window))\n",
    "print(\"stride : {}\".format(stride))\n",
    "print(\"dynamic_channels : {}\".format(dynamic_channels))\n",
    "print(\"static_channels : {}\".format(static_channels))\n",
    "print(\"output_channels : {}\".format(output_channels))\n",
    "print(\"unknown : {}\".format(unknown))\n",
    "print(\"model_name : {}\".format(model_name))\n",
    "print(\"forward_code_dim : {}\".format(forward_code_dim))\n",
    "print(\"latent_code_dim : {}\".format(latent_code_dim))\n",
    "print(\"device : {}\".format(device))\n",
    "print(\"dropout : {}\".format(dropout))\n",
    "print(\"train : {}\".format(train))\n",
    "print(\"batch_size : {}\".format(batch_size))\n",
    "print(\"epochs : {}\".format(epochs))\n",
    "print(\"learning_rate : {}\".format(learning_rate))\n",
    "print(\"meta_learning_rate : {}\".format(meta_learning_rate))\n",
    "print(\"num_inner_steps : {}\".format(num_inner_steps))\n",
    "print(\"init : {}\".format(init))\n",
    "print(\"fold : {}\".format(fold))\n",
    "print(\"max_patience : {}\".format(max_patience))\n",
    "print(\"few_shot_years : {}\".format(few_shot_years))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-harbor",
   "metadata": {},
   "source": [
    "# DEFINE DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-glucose",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATE = args.date\n",
    "PREPROCESSED_DIR = config.PREPROCESSED_DIR\n",
    "RESULT_DIR = os.path.join(config.RESULT_DIR, DATE)\n",
    "MODEL_DIR = os.path.join(config.MODEL_DIR, DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-admission",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file):\n",
    "    dataset = np.load(os.path.join(PREPROCESSED_DIR, \"{}.npz\".format(file)), allow_pickle=True)\n",
    "    return dataset\n",
    "\n",
    "def get_data(dataset, index, preprocessed=True,fold=0):\n",
    "    data = dataset[\"data\"]\n",
    "    if preprocessed:\n",
    "        data_mean = dataset[\"train_data_means\"][fold]\n",
    "        data_std =  dataset[\"train_data_stds\"][fold]\n",
    "\n",
    "        normalized_data = np.zeros_like(data)\n",
    "        for feature in range(data_mean.shape[0]):\n",
    "            if data_std[feature]!=0:\n",
    "                normalized_data[:,:,:,feature] = (data[:,:,:,feature] - data_mean[feature])/data_std[feature]\n",
    "            else:\n",
    "                normalized_data[:,:,:,feature] = data[:,:,:,feature]\n",
    "        data = normalized_data\n",
    "    data = np.nan_to_num(data, nan=unknown)\n",
    "    data = data[dataset[index][fold]]\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-accreditation",
   "metadata": {},
   "source": [
    "# TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    print(\"fold:{}\\tinit:{}\".format(fold, init))\n",
    "\n",
    "    # BUILD MODEL\n",
    "    inverse_model = getattr(MODEL, \"ae\")(input_channels=len(dynamic_channels)+len(output_channels), code_dim=latent_code_dim, hidden_dim=latent_code_dim, output_channels=len(static_channels), device=device)\n",
    "    inverse_model = inverse_model.to(device)\n",
    "    pytorch_total_params = sum(p.numel() for p in inverse_model.parameters() if p.requires_grad)\n",
    "    print(inverse_model)\n",
    "    forward_model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "    forward_model = forward_model.to(device)\n",
    "    pytorch_total_params += sum(p.numel() for p in forward_model.parameters() if p.requires_grad)\n",
    "    print(forward_model)\n",
    "    print(\"#Parameters:{}\".format(pytorch_total_params))\n",
    "    criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "    optimizer_embedding = torch.optim.Adam(list(inverse_model.parameters()), lr=meta_learning_rate)\n",
    "    optimizer_forward = torch.optim.Adam(list(forward_model.parameters()), lr=meta_learning_rate)\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    min_loss = 10000\n",
    "    patience = 0 \n",
    "\n",
    "    for epoch in range(1,epochs+1):\n",
    "        \n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # LOSS ON TRAIN SET\n",
    "        inverse_model.train()\n",
    "        forward_model.train()\n",
    "\n",
    "        # LOAD DATA\n",
    "        file, index = \"strided_train\", \"in_indices\"\n",
    "        dataset = load_dataset(file)\n",
    "        data = get_data(dataset, index,fold=fold)\n",
    "        nodes, years, window, channels = data.shape\n",
    "        \n",
    "        #Create a random vector and repeat it across years and windows for CTLSTM\n",
    "        np.random.seed(0)\n",
    "        # random_static_data = np.random.normal(0, 1, size = (nodes, latent_code_dim))\n",
    "        # random_static_data = np.repeat(random_static_data[:, np.newaxis,np.newaxis],window,axis=2)\n",
    "        # print(nodes, years, window, channels)\n",
    "\n",
    "        # LOSS\n",
    "        epoch_loss = 0\n",
    "\n",
    "        #Get instance for each node\n",
    "        node_data = data[np.arange(nodes)]\n",
    "        # random_static_data = random_static_data[np.arange(nodes)]\n",
    "        # print(node_data.shape)\n",
    "\n",
    "        random_batches = random.sample(range(node_data.shape[0]),node_data.shape[0])\n",
    "        for batch in range(math.ceil(nodes/batch_size)):\n",
    "            batch_loss = []\n",
    "\n",
    "\n",
    "            \n",
    "            random_batch = random_batches[batch*batch_size:(batch+1)*batch_size]\n",
    "            batch_data = torch.from_numpy(node_data[random_batch]).to(device)\n",
    "            # batch_random_static_data = torch.from_numpy(random_static_data[random_batch]).to(device)\n",
    "            \n",
    "\n",
    "            # GET BATCH DATA AND LABEL\n",
    "            batch_support_data, batch_query_data = UTILS.datsetSupportQuerry(batch_data)\n",
    "            \n",
    "            \n",
    "            for i in range(batch_support_data.shape[0]):\n",
    "                \n",
    "                # GET Basin support and query data\n",
    "                basin_support_data, basin_query_data = batch_support_data[i], batch_query_data[i]\n",
    "                # basin_random_static_data = batch_random_static_data[i]\n",
    "                \n",
    "                basin_dynamic_support_input = basin_support_data[:, :, dynamic_channels].to(device)\n",
    "                basin_dynamic_support_input_output = basin_support_data[:, :, dynamic_channels+output_channels].to(device)\n",
    "                basin_static_data,_,_,_ = inverse_model(x=basin_dynamic_support_input_output)               \n",
    "                basin_static_data = torch.mean(basin_static_data,axis=0)\n",
    "                basin_static_support_input = torch.repeat_interleave(basin_static_data.unsqueeze(0),basin_dynamic_support_input.shape[0],axis=0).to(device)\n",
    "                basin_static_support_input = torch.repeat_interleave(basin_static_support_input.unsqueeze(1),window,axis=1).to(device)\n",
    "                # basin_static_support_input = basin_support_data[:, :, static_channels].to(device)\n",
    "                basin_support_label = basin_support_data[:, :, output_channels].to(device)\n",
    "                \n",
    "                basin_dynamic_query_input = basin_query_data[:, :, dynamic_channels].to(device)\n",
    "                basin_dynamic_query_input_output = basin_query_data[:, :, dynamic_channels+output_channels].to(device)\n",
    "                basin_static_query_input = torch.repeat_interleave(basin_static_data.unsqueeze(0),basin_dynamic_query_input.shape[0],axis=0).to(device)\n",
    "                basin_static_query_input = torch.repeat_interleave(basin_static_query_input.unsqueeze(1),window,axis=1).to(device)\n",
    "                basin_query_label = basin_query_data[:, :, output_channels].to(device)\n",
    "                \n",
    "                basin_model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "                basin_model = basin_model.to(device)\n",
    "                basin_model.load_state_dict(forward_model.state_dict())\n",
    "                \n",
    "                for step in range(num_inner_steps):\n",
    "                    \n",
    "                    # GET OUTPUT\n",
    "                    # print(basin_dynamic_support_input.shape,basin_static_support_input.shape)\n",
    "                    batch_pred = forward_model(x_dynamic=basin_dynamic_support_input, x_static=basin_static_support_input.float() )\n",
    "                    # print(batch_pred.shape)\n",
    "\n",
    "                    # CALCULATE LOSS\n",
    "                    basin_loss = criterion(basin_support_label, batch_pred)\t\t\t\t\t\t\t\t\t\t\t# PER CHANNEL LOSS\n",
    "                    mask = (basin_support_label!=unknown).float()\t\t\t\t\t\t\t\t\t\t\t\t\t# CREATE MASK\n",
    "                    basin_loss = basin_loss * mask\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# MULTIPLY MASK\n",
    "                    basin_loss, mask = torch.sum(basin_loss, dim=2), (torch.sum(mask, dim=2)>0).float()\t\t# PER INSTANCE LOSS\n",
    "                    basin_loss = torch.sum(basin_loss)/torch.sum(mask)\t\t\t\t\t\t\t\t\t\t# MEAN SEQUENCE LOSS\n",
    "                    \n",
    "                    # LOSS BACKPROPOGATE\n",
    "                    grad = torch.autograd.grad(basin_loss, forward_model.parameters(),create_graph=True, allow_unused=True)\n",
    "                    fast_weights = list(map(lambda p: p[1] - learning_rate * p[0], zip(grad, forward_model.parameters())))\n",
    "                    for param, fast_params in zip(forward_model.parameters(), fast_weights):\n",
    "                        param.data = fast_params\n",
    "            \n",
    "\n",
    "                \n",
    "                # GET OUTPUT\n",
    "                batch_pred = forward_model(x_dynamic=basin_dynamic_query_input, x_static=basin_static_query_input.float() )\n",
    "                # print(batch_pred.shape)\n",
    "\n",
    "                # CALCULATE LOSS\n",
    "                basin_loss = criterion(basin_query_label, batch_pred)\t\t\t\t\t\t\t\t\t\t\t# PER CHANNEL LOSS\n",
    "                mask = (basin_query_label!=unknown).float()\t\t\t\t\t\t\t\t\t\t\t\t\t# CREATE MASK\n",
    "                basin_loss = basin_loss * mask\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# MULTIPLY MASK\n",
    "                basin_loss, mask = torch.sum(basin_loss, dim=2), (torch.sum(mask, dim=2)>0).float()\t\t# PER INSTANCE LOSS\n",
    "                basin_loss = torch.sum(basin_loss)/torch.sum(mask)\t\t\t\t\t\t\t\t\t\t# MEAN SEQUENCE LOSS\n",
    "                \n",
    "                batch_loss.append(basin_loss)\n",
    "\n",
    "                # RESET MODEL FOR NEXT TASK\n",
    "                forward_model.load_state_dict(basin_model.state_dict())\n",
    "                \n",
    "            # LOSS BACKPROPOGATE\n",
    "            batch_loss = torch.stack(batch_loss).mean(0) \n",
    "            optimizer_forward.zero_grad()\n",
    "            optimizer_embedding.zero_grad()        \n",
    "            batch_loss.backward()\n",
    "            optimizer_embedding.step()\n",
    "            optimizer_forward.step()\n",
    "\n",
    "            # AGGREGATE LOSS\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "        epoch_loss /= ((batch+1))\n",
    "        print('Epoch:{}\\tTrain Loss:{:.4f}'.format(epoch, epoch_loss), end=\"\\t\")\n",
    "        train_loss.append(epoch_loss)\n",
    "\n",
    "        # SCORE ON VALIDATION SET\n",
    "        \n",
    "        inverse_model.eval()\n",
    "        forward_model.eval()\n",
    "\n",
    "        # LOAD DATA\n",
    "        file, index = \"strided_valid\", \"in_indices\"\n",
    "        dataset = load_dataset(file)\n",
    "        data = get_data(dataset, index,fold=fold)\n",
    "        nodes, years, window, channels = data.shape\n",
    "        # print(nodes, years, window, channels)\n",
    "\n",
    "       # LOSS\n",
    "        epoch_loss = 0\n",
    "\n",
    "        #Get instance for each node\n",
    "        node_data = data[np.arange(nodes)]\n",
    "        # print(node_data.shape)\n",
    "\n",
    "        random_batches = random.sample(range(node_data.shape[0]),node_data.shape[0])\n",
    "        for batch in range(math.ceil(nodes/batch_size)):\n",
    "            batch_loss = []\n",
    "\n",
    "            \n",
    "            random_batch = random_batches[batch*batch_size:(batch+1)*batch_size]\n",
    "            batch_data = torch.from_numpy(node_data[random_batch]).to(device)\n",
    "            batch_random_static_data = torch.from_numpy(random_static_data[random_batch]).to(device)\n",
    "            \n",
    "\n",
    "            # GET BATCH DATA AND LABEL\n",
    "            batch_support_data, batch_query_data = UTILS.datsetSupportQuerry(batch_data)\n",
    "            \n",
    "            \n",
    "            for i in range(batch_support_data.shape[0]):\n",
    "                # print(f\"VAL_epoch_{epoch}\\tbasin_{i}\")\n",
    "                \n",
    "                # GET Basin support and query data\n",
    "                basin_support_data, basin_query_data = batch_support_data[i], batch_query_data[i]\n",
    "                basin_random_static_data = batch_random_static_data[i]\n",
    "                \n",
    "                basin_dynamic_support_input = basin_support_data[:, :, dynamic_channels].to(device)\n",
    "                basin_dynamic_support_input_output = basin_support_data[:, :, dynamic_channels+output_channels].to(device)\n",
    "                basin_static_data,_,_,_ = inverse_model(x=basin_dynamic_support_input_output)               \n",
    "                basin_static_data = torch.mean(basin_static_data,axis=0)\n",
    "                basin_static_support_input = torch.repeat_interleave(basin_static_data.unsqueeze(0),basin_dynamic_support_input.shape[0],axis=0).to(device)\n",
    "                basin_static_support_input = torch.repeat_interleave(basin_static_support_input.unsqueeze(1),window,axis=1).to(device)\n",
    "                # basin_static_support_input = basin_support_data[:, :, static_channels].to(device)\n",
    "                basin_support_label = basin_support_data[:, :, output_channels].to(device)\n",
    "                \n",
    "                basin_dynamic_query_input = basin_query_data[:, :, dynamic_channels].to(device)\n",
    "                basin_dynamic_query_input_output = basin_query_data[:, :, dynamic_channels+output_channels].to(device)\n",
    "                basin_static_query_input = torch.repeat_interleave(basin_static_data.unsqueeze(0),basin_dynamic_query_input.shape[0],axis=0).to(device)\n",
    "                basin_static_query_input = torch.repeat_interleave(basin_static_query_input.unsqueeze(1),window,axis=1).to(device)\n",
    "                basin_query_label = basin_query_data[:, :, output_channels].to(device)\n",
    "                \n",
    "                basin_model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "                basin_model = basin_model.to(device)\n",
    "                basin_model.load_state_dict(forward_model.state_dict())\n",
    "                \n",
    "                for step in range(num_inner_steps):\n",
    "                    \n",
    "                    # GET OUTPUT\n",
    "                    # print(basin_dynamic_support_input.shape,basin_static_support_input)\n",
    "                    batch_pred = forward_model(x_dynamic=basin_dynamic_support_input, x_static=basin_static_support_input.float() )\n",
    "                    # print(batch_pred.shape)\n",
    "\n",
    "                    # CALCULATE LOSS\n",
    "                    basin_loss = criterion(basin_support_label, batch_pred)\t\t\t\t\t\t\t\t\t\t\t# PER CHANNEL LOSS\n",
    "                    mask = (basin_support_label!=unknown).float()\t\t\t\t\t\t\t\t\t\t\t\t\t# CREATE MASK\n",
    "                    basin_loss = basin_loss * mask\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# MULTIPLY MASK\n",
    "                    basin_loss, mask = torch.sum(basin_loss, dim=2), (torch.sum(mask, dim=2)>0).float()\t\t# PER INSTANCE LOSS\n",
    "                    basin_loss = torch.sum(basin_loss)/torch.sum(mask)\t\t\t\t\t\t\t\t\t\t# MEAN SEQUENCE LOSS\n",
    "                    \n",
    "                    # LOSS BACKPROPOGATE\n",
    "                    grad = torch.autograd.grad(basin_loss, forward_model.parameters(),create_graph=True, allow_unused=True)\n",
    "                    fast_weights = list(map(lambda p: p[1] - learning_rate * p[0], zip(grad, forward_model.parameters())))\n",
    "                    for param, fast_params in zip(forward_model.parameters(), fast_weights):\n",
    "                        param.data = fast_params\n",
    "            \n",
    "\n",
    "                \n",
    "                # GET OUTPUT\n",
    "                batch_pred = forward_model(x_dynamic=basin_dynamic_query_input, x_static=basin_static_query_input.float() )\n",
    "                # print(batch_pred.shape)\n",
    "\n",
    "                # CALCULATE LOSS\n",
    "                basin_loss = criterion(basin_query_label, batch_pred)\t\t\t\t\t\t\t\t\t\t\t# PER CHANNEL LOSS\n",
    "                mask = (basin_query_label!=unknown).float()\t\t\t\t\t\t\t\t\t\t\t\t\t# CREATE MASK\n",
    "                basin_loss = basin_loss * mask\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# MULTIPLY MASK\n",
    "                basin_loss, mask = torch.sum(basin_loss, dim=2), (torch.sum(mask, dim=2)>0).float()\t\t# PER INSTANCE LOSS\n",
    "                basin_loss = torch.sum(basin_loss)/torch.sum(mask)\t\t\t\t\t\t\t\t\t\t# MEAN SEQUENCE LOSS\n",
    "                \n",
    "                batch_loss.append(basin_loss)\n",
    "\n",
    "                # RESET MODEL FOR NEXT TASK\n",
    "                forward_model.load_state_dict(basin_model.state_dict())\n",
    "                \n",
    "            batch_loss = torch.stack(batch_loss).mean(0)  \n",
    "            # AGGREGATE LOSS\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "        epoch_loss /= ((batch+1))\n",
    "        print(\"Val Loss:{:.4f}\\tMin Loss:{:.4f}\\tPatience:{}\".format(epoch_loss, min_loss, patience), end=\"\\t\")\n",
    "        valid_loss.append(epoch_loss)\n",
    "        if min_loss>epoch_loss:\n",
    "            min_loss = epoch_loss\n",
    "            torch.save(inverse_model.state_dict(), os.path.join(MODEL_DIR, \"{}_inverse\".format(model_name)))\n",
    "            torch.save(forward_model.state_dict(), os.path.join(MODEL_DIR, \"{}_forward\".format(model_name)))\n",
    "            \n",
    "            patience = 0\n",
    "        else:\n",
    "            patience+=1\n",
    "        if patience>max_patience:\n",
    "            break\n",
    "        end = time.time()\n",
    "        print(\"Time:{:.4f}\".format(end-start))\n",
    "\n",
    "    # PLOT LOSS\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.set_xlabel(\"#Epoch\", fontsize=50)\n",
    "\n",
    "    # PLOT TRAIN LOSS\n",
    "    lns1 = ax1.plot(train_loss, color='red', marker='o', linewidth=4, label=\"TRAIN LOSS\")\n",
    "\n",
    "    # PLOT VALIDATION SCORE\n",
    "    ax2 = ax1.twinx()\n",
    "    lns2 = ax2.plot(valid_loss, color='blue', marker='o', linewidth=4, label=\"VAL LOSS\")\n",
    "\n",
    "    # added these three lines\n",
    "    lns = lns1+lns2\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc=\"upper right\", fontsize=40, frameon=False)\n",
    "\n",
    "    plt.tight_layout(pad=0.0,h_pad=0.0,w_pad=0.0)\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"{}_SCORE.pdf\".format(model_name)), format = \"pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-editing",
   "metadata": {},
   "source": [
    "# TEST MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-final",
   "metadata": {},
   "source": [
    "## IN DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IN\\tfold:{}\\tinit:{}\".format(fold, init))\n",
    "start = time.time()\n",
    "\n",
    "# BUILD MODEL\n",
    "inverse_model = getattr(MODEL, \"ae\")(input_channels=len(dynamic_channels)+len(output_channels), code_dim=latent_code_dim, hidden_dim=latent_code_dim, output_channels=len(static_channels), device=device)\n",
    "inverse_model = inverse_model.to(device)\n",
    "pytorch_total_params = sum(p.numel() for p in inverse_model.parameters() if p.requires_grad)\n",
    "print(inverse_model)\n",
    "forward_model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "forward_model = forward_model.to(device)\n",
    "pytorch_total_params += sum(p.numel() for p in forward_model.parameters() if p.requires_grad)\n",
    "print(forward_model)\n",
    "print(\"#Parameters:{}\".format(pytorch_total_params))\n",
    "criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "optimizer_embedding = torch.optim.Adam(list(inverse_model.parameters()), lr=meta_learning_rate)\n",
    "optimizer_forward = torch.optim.Adam(list(forward_model.parameters()), lr=meta_learning_rate)\n",
    "# print(\"#Parameters:{}\".format(pytorch_total_params))\n",
    "# print(model)\n",
    "\n",
    "# LOAD MODEL\n",
    "inverse_model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"{}_forward\".format(model_name))))\n",
    "inverse_model.eval()\n",
    "forward_model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"{}_inverse\".format(model_name))))\n",
    "forward_model.eval()\n",
    "\n",
    "# LOAD Few shot DATA\n",
    "file, index = \"strided_train\", \"in_indices\"\n",
    "dataset = load_dataset(file)\n",
    "data = get_data(dataset, index,fold=fold)[:,-(few_shot_years*2-1):]\n",
    "nodes, years, window, channels = data.shape\n",
    "# print(nodes, years, window, channels)\n",
    "\n",
    "# LOAD DATA\n",
    "file, index = \"strided_test\", \"in_indices\"\n",
    "dataset = load_dataset(file)\n",
    "data_test = get_data(dataset, index,fold=fold)\n",
    "nodes, years, window, channels = data_test.shape\n",
    "\n",
    "np.random.seed(0)\n",
    "# static_data = np.random.normal(0, 1, size = (nodes, latent_code_dim))\n",
    "# static_data = np.repeat(static_data[:, np.newaxis,np.newaxis],window,axis=2)\n",
    "\n",
    "dataset_true = unknown*np.ones((nodes, years, window, len(output_channels)), dtype=np.float32)\n",
    "dataset_pred = unknown*np.ones((nodes, years, window, len(output_channels)), dtype=np.float32)\n",
    "\n",
    "\n",
    "#Get instance for each node\n",
    "node_data_train = data[np.arange(nodes)]\n",
    "node_data_test = data_test[np.arange(nodes)]\n",
    "# print(node_data.shape)\n",
    "\n",
    "node_data_train = torch.from_numpy(node_data_train).to(device)\n",
    "node_data_test = torch.from_numpy(node_data_test).to(device)\n",
    "# static_data = torch.from_numpy(static_data).to(device)\n",
    "\n",
    "\n",
    "support_data, query_data = node_data_train,node_data_test\n",
    "\n",
    "# print(support_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(nodes):\n",
    "    print(i)\n",
    "\n",
    "    # GET Basin support and query data\n",
    "    basin_support_data, basin_query_data = support_data[i], query_data[i]\n",
    "    \n",
    "    # print(basin_support_data.shape)\n",
    "    # print(basin_query_data.shape)\n",
    "    \n",
    "    basin_dynamic_support_input = basin_support_data[:, :, dynamic_channels].to(device)\n",
    "    basin_dynamic_support_input_output = basin_support_data[:, :, dynamic_channels+output_channels].to(device)\n",
    "    basin_static_data,_,_,_ = inverse_model(x=basin_dynamic_support_input_output)               \n",
    "    basin_static_data = torch.mean(basin_static_data,axis=0)\n",
    "    basin_static_support_input = torch.repeat_interleave(basin_static_data.unsqueeze(0),basin_dynamic_support_input.shape[0],axis=0).to(device)\n",
    "    basin_static_support_input = torch.repeat_interleave(basin_static_support_input.unsqueeze(1),window,axis=1).to(device)\n",
    "    # basin_static_support_input = basin_support_data[:, :, static_channels].to(device)\n",
    "    basin_support_label = basin_support_data[:, :, output_channels].to(device)\n",
    "\n",
    "    basin_dynamic_query_input = basin_query_data[:, :, dynamic_channels].to(device)\n",
    "    basin_dynamic_query_input_output = basin_query_data[:, :, dynamic_channels+output_channels].to(device)\n",
    "    basin_static_query_input = torch.repeat_interleave(basin_static_data.unsqueeze(0),basin_dynamic_query_input.shape[0],axis=0).to(device)\n",
    "    basin_static_query_input = torch.repeat_interleave(basin_static_query_input.unsqueeze(1),window,axis=1).to(device)\n",
    "    basin_query_label = basin_query_data[:, :, output_channels].to(device)\n",
    "\n",
    "    basin_model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "    basin_model = basin_model.to(device)\n",
    "    basin_model.load_state_dict(forward_model.state_dict())\n",
    "\n",
    "    for step in range(num_inner_steps):\n",
    "\n",
    "        # GET OUTPUT\n",
    "        # print(basin_dynamic_support_input.shape,basin_static_support_input)\n",
    "        batch_pred = forward_model(x_dynamic=basin_dynamic_support_input, x_static=basin_static_support_input.float() )\n",
    "        # print(batch_pred.shape)\n",
    "\n",
    "        # CALCULATE LOSS\n",
    "        basin_loss = criterion(basin_support_label, batch_pred)\t\t\t\t\t\t\t\t\t\t\t# PER CHANNEL LOSS\n",
    "        mask = (basin_support_label!=unknown).float()\t\t\t\t\t\t\t\t\t\t\t\t\t# CREATE MASK\n",
    "        basin_loss = basin_loss * mask\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# MULTIPLY MASK\n",
    "        basin_loss, mask = torch.sum(basin_loss, dim=2), (torch.sum(mask, dim=2)>0).float()\t\t# PER INSTANCE LOSS\n",
    "        basin_loss = torch.sum(basin_loss)/torch.sum(mask)\t\t\t\t\t\t\t\t\t\t# MEAN SEQUENCE LOSS\n",
    "\n",
    "        # LOSS BACKPROPOGATE\n",
    "        grad = torch.autograd.grad(basin_loss, forward_model.parameters(),create_graph=True, allow_unused=True)\n",
    "        fast_weights = list(map(lambda p: p[1] - learning_rate * p[0], zip(grad, forward_model.parameters())))\n",
    "        for param, fast_params in zip(forward_model.parameters(), fast_weights):\n",
    "            param.data = fast_params\n",
    "\n",
    "\n",
    "\n",
    "    # GET Basin support and query data\n",
    "\n",
    "    batch_pred = forward_model(x_dynamic=basin_dynamic_query_input,x_static=basin_static_query_input.float())\n",
    "    batch_label = basin_query_label\n",
    "\n",
    "    # print(batch_pred.shape)\n",
    "\n",
    "    # STORE OUTPUT\n",
    "    dataset_true[i] = batch_label.detach().cpu().numpy()\n",
    "    dataset_pred[i] = batch_pred.detach().cpu().numpy()\n",
    "\n",
    "dataset_true = (dataset_true*dataset[\"train_data_stds\"][fold][output_channels])+dataset[\"train_data_means\"][fold][output_channels]\n",
    "dataset_pred = (dataset_pred*dataset[\"train_data_stds\"][fold][output_channels])+dataset[\"train_data_means\"][fold][output_channels]\n",
    "dataset_true = UTILS.unstride_array(dataset_true)\n",
    "dataset_pred = UTILS.unstride_array(dataset_pred)\n",
    "dataset_true = dataset_true[:, stride:]\n",
    "dataset_pred = dataset_pred[:, stride:]\n",
    "\n",
    "per_sample_RMSE = UTILS.per_sample_RMSE(dataset_true, dataset_pred, unknown)\n",
    "_, per_node_RMSE = UTILS.per_node_RMSE(dataset_true, dataset_pred, unknown)\n",
    "per_sample_R2 = UTILS.per_sample_R2(dataset_true, dataset_pred, unknown)\n",
    "_, per_node_R2 = UTILS.per_node_R2(dataset_true, dataset_pred, unknown)\n",
    "print(\"Per Sample RMSE:{:.4f}\\tPer Node RMSE:{:.4f}\\tPer Sample R2:{:.4f}\\tPer Node R2:{:.4f}\".format(per_sample_RMSE, per_node_RMSE, per_sample_R2, per_node_R2))\n",
    "np.save(os.path.join(RESULT_DIR, \"{}_{}_{}\".format(file, index, \"true_{}\".format(fold))), dataset_true)\n",
    "np.save(os.path.join(RESULT_DIR, \"{}_{}_{}_{}\".format(file, index, few_shot_years, model_name)), dataset_pred)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time:{:.4f}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OUT\\tfold:{}\\tinit:{}\".format(fold, init))\n",
    "start = time.time()\n",
    "\n",
    "# BUILD MODEL\n",
    "inverse_model = getattr(MODEL, \"ae\")(input_channels=len(dynamic_channels)+len(output_channels), code_dim=latent_code_dim, hidden_dim=latent_code_dim, output_channels=len(static_channels), device=device)\n",
    "inverse_model = inverse_model.to(device)\n",
    "pytorch_total_params = sum(p.numel() for p in inverse_model.parameters() if p.requires_grad)\n",
    "print(inverse_model)\n",
    "forward_model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "forward_model = forward_model.to(device)\n",
    "pytorch_total_params += sum(p.numel() for p in forward_model.parameters() if p.requires_grad)\n",
    "print(forward_model)\n",
    "print(\"#Parameters:{}\".format(pytorch_total_params))\n",
    "criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "optimizer_embedding = torch.optim.Adam(list(inverse_model.parameters()), lr=meta_learning_rate)\n",
    "optimizer_forward = torch.optim.Adam(list(forward_model.parameters()), lr=meta_learning_rate)\n",
    "# print(\"#Parameters:{}\".format(pytorch_total_params))\n",
    "# print(model)\n",
    "\n",
    "# LOAD MODEL\n",
    "inverse_model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"{}_forward\".format(model_name))))\n",
    "inverse_model.eval()\n",
    "forward_model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"{}_inverse\".format(model_name))))\n",
    "forward_model.eval()\n",
    "\n",
    "# LOAD Few shot DATA\n",
    "file, index = \"strided_train\", \"out_indices\"\n",
    "dataset = load_dataset(file)\n",
    "data = get_data(dataset, index,fold=fold)[:,-(few_shot_years*2-1):]\n",
    "nodes, years, window, channels = data.shape\n",
    "# print(nodes, years, window, channels)\n",
    "\n",
    "# LOAD DATA\n",
    "file, index = \"strided_test\", \"out_indices\"\n",
    "dataset = load_dataset(file)\n",
    "data_test = get_data(dataset, index,fold=fold)\n",
    "nodes, years, window, channels = data_test.shape\n",
    "\n",
    "np.random.seed(0)\n",
    "# static_data = np.random.normal(0, 1, size = (nodes, latent_code_dim))\n",
    "# static_data = np.repeat(static_data[:, np.newaxis,np.newaxis],window,axis=2)\n",
    "\n",
    "dataset_true = unknown*np.ones((nodes, years, window, len(output_channels)), dtype=np.float32)\n",
    "dataset_pred = unknown*np.ones((nodes, years, window, len(output_channels)), dtype=np.float32)\n",
    "\n",
    "\n",
    "#Get instance for each node\n",
    "node_data_train = data[np.arange(nodes)]\n",
    "node_data_test = data_test[np.arange(nodes)]\n",
    "# print(node_data.shape)\n",
    "\n",
    "node_data_train = torch.from_numpy(node_data_train).to(device)\n",
    "node_data_test = torch.from_numpy(node_data_test).to(device)\n",
    "# static_data = torch.from_numpy(static_data).to(device)\n",
    "\n",
    "\n",
    "support_data, query_data = node_data_train,node_data_test\n",
    "\n",
    "# print(support_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(nodes):\n",
    "    print(i)\n",
    "\n",
    "    # GET Basin support and query data\n",
    "    basin_support_data, basin_query_data = support_data[i], query_data[i]\n",
    "    \n",
    "    # print(basin_support_data.shape)\n",
    "    # print(basin_query_data.shape)\n",
    "    \n",
    "    basin_dynamic_support_input = basin_support_data[:, :, dynamic_channels].to(device)\n",
    "    basin_dynamic_support_input_output = basin_support_data[:, :, dynamic_channels+output_channels].to(device)\n",
    "    basin_static_data,_,_,_ = inverse_model(x=basin_dynamic_support_input_output)               \n",
    "    basin_static_data = torch.mean(basin_static_data,axis=0)\n",
    "    basin_static_support_input = torch.repeat_interleave(basin_static_data.unsqueeze(0),basin_dynamic_support_input.shape[0],axis=0).to(device)\n",
    "    basin_static_support_input = torch.repeat_interleave(basin_static_support_input.unsqueeze(1),window,axis=1).to(device)\n",
    "    # basin_static_support_input = basin_support_data[:, :, static_channels].to(device)\n",
    "    basin_support_label = basin_support_data[:, :, output_channels].to(device)\n",
    "\n",
    "    basin_dynamic_query_input = basin_query_data[:, :, dynamic_channels].to(device)\n",
    "    basin_dynamic_query_input_output = basin_query_data[:, :, dynamic_channels+output_channels].to(device)\n",
    "    basin_static_query_input = torch.repeat_interleave(basin_static_data.unsqueeze(0),basin_dynamic_query_input.shape[0],axis=0).to(device)\n",
    "    basin_static_query_input = torch.repeat_interleave(basin_static_query_input.unsqueeze(1),window,axis=1).to(device)\n",
    "    basin_query_label = basin_query_data[:, :, output_channels].to(device)\n",
    "\n",
    "    basin_model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "    basin_model = basin_model.to(device)\n",
    "    basin_model.load_state_dict(forward_model.state_dict())\n",
    "\n",
    "    for step in range(num_inner_steps):\n",
    "\n",
    "        # GET OUTPUT\n",
    "        # print(basin_dynamic_support_input.shape,basin_static_support_input)\n",
    "        batch_pred = forward_model(x_dynamic=basin_dynamic_support_input, x_static=basin_static_support_input.float() )\n",
    "        # print(batch_pred.shape)\n",
    "\n",
    "        # CALCULATE LOSS\n",
    "        basin_loss = criterion(basin_support_label, batch_pred)\t\t\t\t\t\t\t\t\t\t\t# PER CHANNEL LOSS\n",
    "        mask = (basin_support_label!=unknown).float()\t\t\t\t\t\t\t\t\t\t\t\t\t# CREATE MASK\n",
    "        basin_loss = basin_loss * mask\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# MULTIPLY MASK\n",
    "        basin_loss, mask = torch.sum(basin_loss, dim=2), (torch.sum(mask, dim=2)>0).float()\t\t# PER INSTANCE LOSS\n",
    "        basin_loss = torch.sum(basin_loss)/torch.sum(mask)\t\t\t\t\t\t\t\t\t\t# MEAN SEQUENCE LOSS\n",
    "\n",
    "        # LOSS BACKPROPOGATE\n",
    "        grad = torch.autograd.grad(basin_loss, forward_model.parameters(),create_graph=True, allow_unused=True)\n",
    "        fast_weights = list(map(lambda p: p[1] - learning_rate * p[0], zip(grad, forward_model.parameters())))\n",
    "        for param, fast_params in zip(forward_model.parameters(), fast_weights):\n",
    "            param.data = fast_params\n",
    "\n",
    "\n",
    "\n",
    "    # GET Basin support and query data\n",
    "\n",
    "    batch_pred = forward_model(x_dynamic=basin_dynamic_query_input,x_static=basin_static_query_input.float())\n",
    "    batch_label = basin_query_label\n",
    "\n",
    "    # print(batch_pred.shape)\n",
    "\n",
    "    # STORE OUTPUT\n",
    "    dataset_true[i] = batch_label.detach().cpu().numpy()\n",
    "    dataset_pred[i] = batch_pred.detach().cpu().numpy()\n",
    "\n",
    "dataset_true = (dataset_true*dataset[\"train_data_stds\"][fold][output_channels])+dataset[\"train_data_means\"][fold][output_channels]\n",
    "dataset_pred = (dataset_pred*dataset[\"train_data_stds\"][fold][output_channels])+dataset[\"train_data_means\"][fold][output_channels]\n",
    "dataset_true = UTILS.unstride_array(dataset_true)\n",
    "dataset_pred = UTILS.unstride_array(dataset_pred)\n",
    "dataset_true = dataset_true[:, stride:]\n",
    "dataset_pred = dataset_pred[:, stride:]\n",
    "\n",
    "per_sample_RMSE = UTILS.per_sample_RMSE(dataset_true, dataset_pred, unknown)\n",
    "_, per_node_RMSE = UTILS.per_node_RMSE(dataset_true, dataset_pred, unknown)\n",
    "per_sample_R2 = UTILS.per_sample_R2(dataset_true, dataset_pred, unknown)\n",
    "_, per_node_R2 = UTILS.per_node_R2(dataset_true, dataset_pred, unknown)\n",
    "print(\"Per Sample RMSE:{:.4f}\\tPer Node RMSE:{:.4f}\\tPer Sample R2:{:.4f}\\tPer Node R2:{:.4f}\".format(per_sample_RMSE, per_node_RMSE, per_sample_R2, per_node_R2))\n",
    "np.save(os.path.join(RESULT_DIR, \"{}_{}_{}\".format(file, index, \"true_{}\".format(fold))), dataset_true)\n",
    "np.save(os.path.join(RESULT_DIR, \"{}_{}_{}_{}\".format(file, index, few_shot_years, model_name)), dataset_pred)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time:{:.4f}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file, index = \"strided_train\", \"test_index\"\n",
    "# dataset = load_dataset(file)\n",
    "# dataset_processed_data = get_data(dataset, index, preprocessed=False,dataset_fold=dataset_fold)\n",
    "# dataset_processed_data = data_normalize(dataset_processed_data,norm_region)[:,:,:,:-1]     \n",
    "# dataset_processed_data = dataset_processed_data[:10]  \n",
    "# lakes, years, window, channels = dataset_processed_data.shape\n",
    "# dataset_obs = get_data(dataset, index, preprocessed=False,dataset_fold=dataset_fold)\n",
    "# dataset_obs = data_normalize(dataset_obs,norm_region)[:,:,:,-1]   \n",
    "# dataset_obs = dataset_obs[:10] \n",
    "# batch_processed_data_support, batch_obs_support =  dataset_processed_data, dataset_obs \n",
    "\n",
    "# file, index = \"strided_test\", \"test_index\"\n",
    "# dataset = load_dataset(file)\n",
    "# dataset_processed_data = get_data(dataset, index, preprocessed=False,dataset_fold=dataset_fold)\n",
    "# dataset_processed_data = data_normalize(dataset_processed_data,norm_region)[:,:,:,:-1]     \n",
    "# dataset_processed_data = dataset_processed_data[:10]  \n",
    "# lakes, years, window, channels = dataset_processed_data.shape\n",
    "# dataset_obs = get_data(dataset, index, preprocessed=False,dataset_fold=dataset_fold)\n",
    "# dataset_obs = data_normalize(dataset_obs,norm_region)[:,:,:,-1]   \n",
    "# dataset_obs = dataset_obs[:10]\n",
    "\n",
    "# total_runs=1\n",
    "# dataset_true = unknown*np.ones((lakes, years, window), dtype=np.float32)\n",
    "# dataset_pred = unknown*np.ones((lakes, years, window), dtype=np.float32)\n",
    "\n",
    "\n",
    "# batch_processed_data_querry, batch_obs_querry = dataset_processed_data, dataset_obs \n",
    "# batch_loss = []\n",
    "# for i,lake in enumerate(batch_lake):\n",
    "#     # GET PARAMETER COPY FOR TASK  \n",
    "#     inverse_model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"{}_inverse\".format(model_name))))\n",
    "#     inverse_model.eval()\n",
    "#     forward_model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"{}_forward\".format(model_name))))\n",
    "#     # GET LAKE DATA\n",
    "#     lake_processed_data_support, lake_obs_support, lake_processed_data_querry, lake_obs_querry = batch_processed_data_support[i], batch_obs_support[i], batch_processed_data_querry[i], batch_obs_querry[i]\n",
    "#     # GET LAKE DATA SUPPORT\n",
    "#     lake_processed_data = torch.from_numpy(lake_processed_data_support).unsqueeze(0).to(device)\n",
    "#     lake_obs = torch.from_numpy(lake_obs_support).unsqueeze(0).to(device)\n",
    "#     # lake_code_vec =  torch.from_numpy(mean_lake_code[lake]).unsqueeze(0).to(device)               \n",
    "\n",
    "#     # GET OUTPUT\n",
    "#     lake_processed_data_dynamic = lake_processed_data[:,  :, :, dynamic_channels]           \n",
    "#     lake_processed_data_static = lake_processed_data[:,  :, :, static_channels] \n",
    "#     lake_processed_data_inputs_embedding = torch.cat((lake_processed_data_dynamic,lake_obs.unsqueeze(-1)),axis = 3)         \n",
    "#     lake_processed_data_inputs_embedding = UTILS.unstride_array(lake_processed_data_inputs_embedding.cpu())             \n",
    "#     lake_processed_data_inputs_embedding = torch.from_numpy(lake_processed_data_inputs_embedding).to(device).float()\n",
    "#     lake_code_vec,_,_ = inverse_model(x=lake_processed_data_inputs_embedding)               \n",
    "#     lake_code_vec_processed =  lake_code_vec.unsqueeze(1).repeat(1, years, 1)   \n",
    "#     lake_code_vec_processed =  lake_code_vec_processed.unsqueeze(2).repeat(1, 1, window, 1) \n",
    "#     for step in range(num_inner_steps):                  \n",
    "#         out = forward_model(x_dynamic=lake_processed_data_dynamic, x_static=lake_code_vec_processed)\n",
    "\n",
    "#         # CALCULATE LOSS\n",
    "#         lake_loss = UTILS.per_lake_loss(y_true=lake_obs, y_pred=out, criterion=criterion, unknown=unknown)\n",
    "\n",
    "#         # LOSS BACKPROPOGATE\n",
    "#         grad = torch.autograd.grad(lake_loss, forward_model.parameters(),create_graph=True, allow_unused=True)\n",
    "# # \t\t\t\tfor (name, param), grad in zip(params.items(), grads):\n",
    "# # \t\t\t\tif grad_clip > 0 and grad is not None:\n",
    "# # \t\t\t\t\tgrad = grad.clamp(min=-grad_clip,max=grad_clip)                \n",
    "#         fast_weights = list(map(lambda p: p[1] - learning_rate * p[0], zip(grad, forward_model.parameters())))\n",
    "#         for param, fast_params in zip(forward_model.parameters(), fast_weights):\n",
    "#             param.data = fast_params\n",
    "\n",
    "#     # GET LAKE DATA QUERRY\n",
    "    \n",
    "#     lake_processed_data = torch.from_numpy(lake_processed_data_querry).unsqueeze(0).to(device)\n",
    "#     lake_obs = torch.from_numpy(lake_obs_querry).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "#     # GET OUTPUT\n",
    "#     lake_processed_data_dynamic = lake_processed_data[:,  :, :, dynamic_channels]\n",
    "#     lake_processed_data_static = lake_processed_data[:,  :, :, static_channels]\n",
    "#     lake_processed_data_inputs_embedding = torch.cat((lake_processed_data_dynamic,lake_obs.unsqueeze(-1)),axis = 3)          \n",
    "#     lake_processed_data_inputs_embedding = UTILS.unstride_array(lake_processed_data_inputs_embedding.cpu())             \n",
    "#     lake_processed_data_inputs_embedding = torch.from_numpy(lake_processed_data_inputs_embedding).to(device).float()\n",
    "#     lake_code_vec,_,_ = inverse_model(x=lake_processed_data_inputs_embedding) \n",
    "#     lake_code_vec_processed =  lake_code_vec.unsqueeze(1).repeat(1, years, 1)   \n",
    "#     lake_code_vec_processed =  lake_code_vec_processed.unsqueeze(2).repeat(1, 1, window, 1)     \n",
    "#     out = forward_model(x_dynamic=lake_processed_data_dynamic, x_static=lake_code_vec_processed)\n",
    "#     # print(out.shape)\n",
    "#     # print(lake_obs.shape)\n",
    "#     lake_loss = UTILS.per_lake_loss(y_true=lake_obs, y_pred=out, criterion=criterion, unknown=unknown)\n",
    "#     batch_loss.append(lake_loss)\n",
    "    \n",
    "    \n",
    "#         # STORE OUTPUT\n",
    "#     dataset_true[i, :,:] = lake_obs.detach().cpu().numpy()\n",
    "#     dataset_pred[i, :,:] = out.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "# # dataset_true_ensemble =   np.mean(dataset_true,axis=-1)   \n",
    "# # dataset_pred_ensemble =   np.mean(dataset_pred,axis=-1) \n",
    "# # print(dataset_true_ensemble.shape)\n",
    "# print(\"TRUE_OBS\",dataset_true.shape)\n",
    "# dataset_true = (dataset_true*dataset[\"train_data_stds\"][output_channels])+dataset[\"train_data_means\"][output_channels]\n",
    "# dataset_pred = (dataset_pred*dataset[\"train_data_stds\"][output_channels])+dataset[\"train_data_means\"][output_channels]\n",
    "\n",
    "# dataset_true = np.expand_dims(dataset_true, axis=3)\n",
    "# dataset_pred = np.expand_dims(dataset_pred, axis=3)\n",
    "\n",
    "# dataset_true = UTILS.unstride_array(dataset_true)\n",
    "# dataset_pred = UTILS.unstride_array(dataset_pred)\n",
    "# dataset_true = dataset_true[:, stride:]\n",
    "# dataset_pred = dataset_pred[:, stride:]\n",
    "\n",
    "# per_sample_RMSE = UTILS.per_sample_RMSE(dataset_true, dataset_pred, unknown)\n",
    "# all_node_RMSE, per_node_RMSE = UTILS.per_node_RMSE(dataset_true, dataset_pred, unknown)\n",
    "# per_sample_R2 = UTILS.per_sample_R2(dataset_true, dataset_pred, unknown)\n",
    "# all_node_r2, per_node_R2 = UTILS.per_node_R2(dataset_true, dataset_pred, unknown)\n",
    "# print(\"Per Sample RMSE:{:.4f}\\tPer Node RMSE:{:.4f}\\tPer Sample R2:{:.4f}\\tPer Node R2:{:.4f}\".format(per_sample_RMSE, per_node_RMSE, per_sample_R2, per_node_R2))\n",
    "# np.save(os.path.join(RESULT_DIR, \"{}_{}_{}\".format(file, index, \"true\")), dataset_true)\n",
    "# np.save(os.path.join(RESULT_DIR, \"{}_{}_{}\".format(file, index, model_name)), dataset_pred)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"IN\\tfold:{}\\tinit:{}\".format(fold, init))\n",
    "# start = time.time()\n",
    "\n",
    "# # BUILD MODEL\n",
    "# model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "# model = model.to(device)\n",
    "# pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "# # print(\"#Parameters:{}\".format(pytorch_total_params))\n",
    "# # print(model)\n",
    "\n",
    "# # LOAD MODEL\n",
    "# model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"{}\".format(model_name))))\n",
    "\n",
    "# # LOAD Few shot DATA\n",
    "# file, index = \"strided_train\", \"in_indices\"\n",
    "# dataset = load_dataset(file)\n",
    "# data = get_data(dataset, index,fold=fold)[:,-(few_shot_years*2-1):]\n",
    "# nodes, years, window, channels = data.shape\n",
    "# # print(nodes, years, window, channels)\n",
    "\n",
    "# # LOAD DATA\n",
    "# file, index = \"strided_test\", \"in_indices\"\n",
    "# dataset = load_dataset(file)\n",
    "# data_test = get_data(dataset, index,fold=fold)\n",
    "# nodes, years, window, channels = data_test.shape\n",
    "\n",
    "# np.random.seed(0)\n",
    "# random_static_data = np.random.normal(0, 1, size = (nodes, latent_code_dim))\n",
    "# random_static_data = np.repeat(random_static_data[:, np.newaxis,np.newaxis],window,axis=2)\n",
    "\n",
    "# dataset_true = unknown*np.ones((nodes, years, window, len(output_channels)), dtype=np.float32)\n",
    "# dataset_pred = unknown*np.ones((nodes, years, window, len(output_channels)), dtype=np.float32)\n",
    "\n",
    "\n",
    "# #Get instance for each node\n",
    "# node_data_train = data[np.arange(nodes)]\n",
    "# node_data_test = data_test[np.arange(nodes)]\n",
    "# # print(node_data.shape)\n",
    "\n",
    "# node_data_train = torch.from_numpy(node_data_train).to(device)\n",
    "# node_data_test = torch.from_numpy(node_data_test).to(device)\n",
    "# random_static_data = torch.from_numpy(random_static_data).to(device)\n",
    "# support_data, query_data = node_data_train,node_data_test\n",
    "\n",
    "# # print(support_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(nodes):\n",
    "#     print(i)\n",
    "\n",
    "#     # GET Basin support and query data\n",
    "#     basin_support_data, basin_query_data = support_data[i], query_data[i]\n",
    "#     basin_random_static_data = random_static_data[i]\n",
    "    \n",
    "#     # print(basin_support_data.shape)\n",
    "#     # print(basin_query_data.shape)\n",
    "    \n",
    "#     basin_dynamic_support_input = basin_support_data[:, :, dynamic_channels].to(device)\n",
    "#     basin_static_support_input = torch.repeat_interleave(basin_random_static_data,basin_dynamic_support_input.shape[0],axis=0).to(device)\n",
    "#     basin_support_label = basin_support_data[:, :, output_channels].to(device)\n",
    "\n",
    "#     basin_dynamic_query_input = basin_query_data[:, :, dynamic_channels].to(device)\n",
    "#     basin_static_query_input = torch.repeat_interleave(basin_random_static_data,basin_dynamic_query_input.shape[0],axis=0).to(device)\n",
    "#     basin_query_label = basin_query_data[:, :, output_channels].to(device)\n",
    "\n",
    "#     basin_model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "#     basin_model = basin_model.to(device)\n",
    "#     basin_model.load_state_dict(model.state_dict())\n",
    "\n",
    "#     for step in range(num_inner_steps):\n",
    "#         # GET OUTPUT\n",
    "#         # print(\"basin_dynamic_support_input\",basin_dynamic_support_input.shape)\n",
    "#         batch_pred = model(x_dynamic=basin_dynamic_support_input,x_static=basin_static_support_input.float())\n",
    "#         # print(batch_pred.shape)\n",
    "\n",
    "#         # CALCULATE LOSS\n",
    "#         basin_loss = criterion(basin_support_label, batch_pred)\t\t\t\t\t\t\t\t\t\t\t# PER CHANNEL LOSS\n",
    "#         mask = (basin_support_label!=unknown).float()\t\t\t\t\t\t\t\t\t\t\t\t\t# CREATE MASK\n",
    "#         basin_loss = basin_loss * mask\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# MULTIPLY MASK\n",
    "#         basin_loss, mask = torch.sum(basin_loss, dim=2), (torch.sum(mask, dim=2)>0).float()\t\t# PER INSTANCE LOSS\n",
    "#         basin_loss = torch.sum(basin_loss)/torch.sum(mask)\t\t\t\t\t\t\t\t\t\t# MEAN SEQUENCE LOSS\n",
    "\n",
    "#         # LOSS BACKPROPOGATE\n",
    "#         grad = torch.autograd.grad(basin_loss, model.parameters(),create_graph=True, allow_unused=True)\n",
    "#         fast_weights = list(map(lambda p: p[1] - learning_rate * p[0], zip(grad, model.parameters())))\n",
    "#         for param, fast_params in zip(model.parameters(), fast_weights):\n",
    "#             param.data = fast_params\n",
    "\n",
    "\n",
    "\n",
    "#     model.eval()\n",
    "#     # GET Basin support and query data\n",
    "\n",
    "#     batch_pred = model(x_dynamic=basin_dynamic_query_input,x_static=basin_static_query_input.float())\n",
    "#     batch_label = basin_query_label\n",
    "\n",
    "#     # print(batch_pred.shape)\n",
    "\n",
    "#     # STORE OUTPUT\n",
    "#     dataset_true[i] = batch_label.detach().cpu().numpy()\n",
    "#     dataset_pred[i] = batch_pred.detach().cpu().numpy()\n",
    "\n",
    "# dataset_true = (dataset_true*dataset[\"train_data_stds\"][fold][output_channels])+dataset[\"train_data_means\"][fold][output_channels]\n",
    "# dataset_pred = (dataset_pred*dataset[\"train_data_stds\"][fold][output_channels])+dataset[\"train_data_means\"][fold][output_channels]\n",
    "# dataset_true = UTILS.unstride_array(dataset_true)\n",
    "# dataset_pred = UTILS.unstride_array(dataset_pred)\n",
    "# dataset_true = dataset_true[:, stride:]\n",
    "# dataset_pred = dataset_pred[:, stride:]\n",
    "\n",
    "# per_sample_RMSE = UTILS.per_sample_RMSE(dataset_true, dataset_pred, unknown)\n",
    "# _, per_node_RMSE = UTILS.per_node_RMSE(dataset_true, dataset_pred, unknown)\n",
    "# per_sample_R2 = UTILS.per_sample_R2(dataset_true, dataset_pred, unknown)\n",
    "# _, per_node_R2 = UTILS.per_node_R2(dataset_true, dataset_pred, unknown)\n",
    "# print(\"Per Sample RMSE:{:.4f}\\tPer Node RMSE:{:.4f}\\tPer Sample R2:{:.4f}\\tPer Node R2:{:.4f}\".format(per_sample_RMSE, per_node_RMSE, per_sample_R2, per_node_R2))\n",
    "# np.save(os.path.join(RESULT_DIR, \"{}_{}_{}\".format(file, index, \"true_{}\".format(fold))), dataset_true)\n",
    "# np.save(os.path.join(RESULT_DIR, \"{}_{}_{}_{}\".format(file, index, few_shot_years, model_name)), dataset_pred)\n",
    "\n",
    "\n",
    "# end = time.time()\n",
    "# print(\"Time:{:.4f}\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-harbor",
   "metadata": {},
   "source": [
    "## OUT DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Out\\tfold:{}\\tinit:{}\".format(fold, init))\n",
    "# start = time.time()\n",
    "\n",
    "# # BUILD MODEL\n",
    "# model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "# model = model.to(device)\n",
    "# pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# # print(\"#Parameters:{}\".format(pytorch_total_params))\n",
    "# # print(model)\n",
    "\n",
    "# # LOAD MODEL\n",
    "# model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"{}\".format(model_name))))\n",
    "\n",
    "# # LOAD Few shot DATA\n",
    "# file, index = \"strided_train\", \"out_indices\"\n",
    "# dataset = load_dataset(file)\n",
    "# data = get_data(dataset, index,fold=fold)[:,-(few_shot_years*2-1):]\n",
    "# nodes, years, window, channels = data.shape\n",
    "# # print(nodes, years, window, channels)\n",
    "\n",
    "# # LOAD DATA\n",
    "# file, index = \"strided_test\", \"out_indices\"\n",
    "# dataset = load_dataset(file)\n",
    "# data_test = get_data(dataset, index,fold=fold)\n",
    "# nodes, years, window, channels = data_test.shape\n",
    "\n",
    "# dataset_true = unknown*np.ones((nodes, years, window, len(output_channels)), dtype=np.float32)\n",
    "# dataset_pred = unknown*np.ones((nodes, years, window, len(output_channels)), dtype=np.float32)\n",
    "\n",
    "\n",
    "# #Get instance for each node\n",
    "# node_data_train = data[np.arange(nodes)]\n",
    "# node_data_test = data_test[np.arange(nodes)]\n",
    "# # print(node_data.shape)\n",
    "\n",
    "# node_data_train = torch.from_numpy(node_data_train).to(device)\n",
    "# node_data_test = torch.from_numpy(node_data_test).to(device)\n",
    "# support_data, query_data = node_data_train,node_data_test\n",
    "\n",
    "# # print(support_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(nodes):\n",
    "#     print(i)\n",
    "\n",
    "#     # GET Basin support and query data\n",
    "#     basin_support_data, basin_query_data = support_data[i], query_data[i]\n",
    "#     # print(basin_support_data.shape)\n",
    "#     # print(basin_query_data.shape)\n",
    "    \n",
    "#     basin_dynamic_support_input = basin_support_data[:, :, dynamic_channels].to(device)\n",
    "#     basin_static_support_input = basin_support_data[:, :, static_channels].to(device)\n",
    "#     basin_support_label = basin_support_data[:, :, output_channels].to(device)\n",
    "\n",
    "#     basin_dynamic_query_input = basin_query_data[:, :, dynamic_channels].to(device)\n",
    "#     basin_static_query_input = basin_query_data[:, :, static_channels].to(device)\n",
    "#     basin_query_label = basin_query_data[:, :, output_channels].to(device)\n",
    "\n",
    "#     basin_model = getattr(MODEL, \"tamlstm\")(input_dynamic_channels=len(dynamic_channels), input_static_channels=latent_code_dim, hidden_dim=forward_code_dim, output_channels=len(output_channels), dropout=dropout)\n",
    "#     basin_model = basin_model.to(device)\n",
    "#     basin_model.load_state_dict(model.state_dict())\n",
    "\n",
    "#     for step in range(num_inner_steps):\n",
    "#         # GET OUTPUT\n",
    "#         # print(\"basin_dynamic_support_input\",basin_dynamic_support_input.shape)\n",
    "#         batch_pred = model(x_dynamic=basin_dynamic_support_input)\n",
    "#         # print(batch_pred.shape)\n",
    "\n",
    "#         # CALCULATE LOSS\n",
    "#         basin_loss = criterion(basin_support_label, batch_pred)\t\t\t\t\t\t\t\t\t\t\t# PER CHANNEL LOSS\n",
    "#         mask = (basin_support_label!=unknown).float()\t\t\t\t\t\t\t\t\t\t\t\t\t# CREATE MASK\n",
    "#         basin_loss = basin_loss * mask\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# MULTIPLY MASK\n",
    "#         basin_loss, mask = torch.sum(basin_loss, dim=2), (torch.sum(mask, dim=2)>0).float()\t\t# PER INSTANCE LOSS\n",
    "#         basin_loss = torch.sum(basin_loss)/torch.sum(mask)\t\t\t\t\t\t\t\t\t\t# MEAN SEQUENCE LOSS\n",
    "\n",
    "#         # LOSS BACKPROPOGATE\n",
    "#         grad = torch.autograd.grad(basin_loss, model.parameters(),create_graph=True, allow_unused=True)\n",
    "#         fast_weights = list(map(lambda p: p[1] - learning_rate * p[0], zip(grad, model.parameters())))\n",
    "#         for param, fast_params in zip(model.parameters(), fast_weights):\n",
    "#             param.data = fast_params\n",
    "\n",
    "\n",
    "\n",
    "#     model.eval()\n",
    "#     # GET Basin support and query data\n",
    "\n",
    "#     batch_pred = model(x_dynamic=basin_dynamic_query_input)\n",
    "#     batch_label = basin_query_label\n",
    "\n",
    "#     # print(batch_pred.shape)\n",
    "\n",
    "#     # STORE OUTPUT\n",
    "#     dataset_true[i] = batch_label.detach().cpu().numpy()\n",
    "#     dataset_pred[i] = batch_pred.detach().cpu().numpy()\n",
    "\n",
    "# dataset_true = (dataset_true*dataset[\"train_data_stds\"][fold][output_channels])+dataset[\"train_data_means\"][fold][output_channels]\n",
    "# dataset_pred = (dataset_pred*dataset[\"train_data_stds\"][fold][output_channels])+dataset[\"train_data_means\"][fold][output_channels]\n",
    "# dataset_true = UTILS.unstride_array(dataset_true)\n",
    "# dataset_pred = UTILS.unstride_array(dataset_pred)\n",
    "# dataset_true = dataset_true[:, stride:]\n",
    "# dataset_pred = dataset_pred[:, stride:]\n",
    "\n",
    "# per_sample_RMSE = UTILS.per_sample_RMSE(dataset_true, dataset_pred, unknown)\n",
    "# _, per_node_RMSE = UTILS.per_node_RMSE(dataset_true, dataset_pred, unknown)\n",
    "# per_sample_R2 = UTILS.per_sample_R2(dataset_true, dataset_pred, unknown)\n",
    "# _, per_node_R2 = UTILS.per_node_R2(dataset_true, dataset_pred, unknown)\n",
    "# print(\"Per Sample RMSE:{:.4f}\\tPer Node RMSE:{:.4f}\\tPer Sample R2:{:.4f}\\tPer Node R2:{:.4f}\".format(per_sample_RMSE, per_node_RMSE, per_sample_R2, per_node_R2))\n",
    "# np.save(os.path.join(RESULT_DIR, \"{}_{}_{}\".format(file, index, \"true_{}\".format(fold))), dataset_true)\n",
    "# np.save(os.path.join(RESULT_DIR, \"{}_{}_{}_{}\".format(file, index, few_shot_years, model_name)), dataset_pred)\n",
    "\n",
    "\n",
    "# end = time.time()\n",
    "# print(\"Time:{:.4f}\".format(end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_a100",
   "language": "python",
   "name": "main_a100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
